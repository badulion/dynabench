from torch.utils.data import Dataset
import os
import h5py
import numpy as np
from math import ceil

class DynaBenchBase(Dataset):
    """
    Handles the data in a pytorch way generated by solving different equations.
    
    Attributes
    ----------
    available_equations: List[str]
        Lists the four different equations available.
    
    available_supports: List[str]
        Lists the possible selection of support points where the function is known
    
    available_tasks: List[str]
        Lists the possible tasks (forecast/evolution)
    
    available_modes: List[str]
        Lists the possible divisions of the data (train/val/test)
    
    num_fields_dict: Dict(str, int)
        Lists the number of target channel (variables) for each equaition

    name: str
        the name of the Benchmark dataset

    mode: str
        the current selected data mode (train/val/test)

    equation: str
        the equation used

    task: str
        the used target task

    support: str
        the used support point selection

    base_path: str
        location where the data is stored

    lookback: int
        How many past states are used to make the prediction. The additional states are concatenated along the channel dimension.

    rollout: int
        How many steps should be predicted in a closed loop setting. Only used for forecast task
    """

    available_equations = ["gas_dynamics", "wave", "kuramoto_sivashinsky", "brusselator"]
    available_supports = ["cloud", "grid"]
    available_num_points = ["low", "high"]
    available_tasks = ["forecast", "evolution"]
    available_modes = ["train", "val", "test"]
    num_fields_dict = {
        "gas_dynamics": 4, 
        "wave": 1, 
        "kuramoto_sivashinsky": 1, 
        "brusselator": 2
    }

    def __init__(
        self,
        name="dyna-benchmark",
        mode="train",
        equation="gas_dynamics",
        task="forecast",
        support="grid",
        num_points="high",
        base_path="data",
        lookback=1,
        rollout=1,
        test_ratio=0.1,
        val_ratio=0.1,
        *args,
        **kwargs,
    ):
        super(DynaBenchBase, self).__init__()
        self.name = name
        self.equation = equation
        self.base_path = base_path
        self.support = support
        self.num_points = num_points
        self.task = task
        self.mode = mode

        if not mode in self.available_modes:
            raise KeyError(f"Mode not available. Select from {self.available_mode}")

        if lookback < 1:
            raise RuntimeError("Lookback cannot be smaller than 1")

        self.lookback = lookback
        self.rollout = rollout

        # support selector
        if not support in self.available_supports:
            raise KeyError(f"Support not available. Select from {self.available_supports}")

        if not num_points in self.available_num_points:
            raise KeyError(f"Num points not available. Select from {self.available_num_points}")

        self.data_selector = f"data_{support}_{num_points}"
        self.points_selector = f"points_{support}_{num_points}"

        # read files
        if not equation in self.available_equations:
            raise KeyError(f"Selected equation not available. Select from {self.available_equations}")
        self.path = os.path.join(self.base_path, self.equation)


        self.num_fields = self.num_fields_dict[self.equation]

        # do it nicer (perhaps not here?)
        if not os.path.exists(self.path):
            raise RuntimeError(f"Data not found. Did you generate the data?")
        if len(os.listdir(self.path)) == 0:
            raise RuntimeError(f"Data not found. Did you generate the data?")


        file_paths_all = os.listdir(self.path)
        file_numbers = [file[:-5] for file in file_paths_all]

        # filter by train/val/test
        num_files = len(file_numbers)
        if num_files < 3 and mode == "train":
            raise RuntimeError(f"Not enough data to split")
        else:
            num_files_test = ceil(num_files*test_ratio)
            num_files_val = ceil(num_files*val_ratio)

        self.file_numbers_train = range(num_files-num_files_test-num_files_val)
        self.file_numbers_val = range(num_files-num_files_test-num_files_val,num_files-num_files_test)
        self.file_numbers_test = range(num_files-num_files_test,num_files)

        if mode == "train":
            self.file_paths = [f"{i}.hdf5" for i in file_numbers if int(i) in self.file_numbers_train]
        elif mode == "val":
            self.file_paths = [f"{i}.hdf5" for i in file_numbers if int(i) in self.file_numbers_val]
        elif mode == "test":
            self.file_paths = [f"{i}.hdf5" for i in file_numbers if int(i) in self.file_numbers_test]

        self.files = [h5py.File(os.path.join(self.path, file_path)) for file_path in self.file_paths]
        self.raw_lengths = [len(file['times']) for file in self.files]
        self.real_lengths = [length - self.lookback - self.rollout+1 for length in self.raw_lengths]
        self.indices_end = np.cumsum(self.real_lengths)
        self.indices_start = self.indices_end - self.real_lengths[0]


    def __getitem__(self, index):
        if index < 0:
            index += len(self)
        if index > len(self) or index < 0:
            raise IndexError("Index out of bounds")
        
        # select appropriate file and indices
        file_selector = next(idx for idx, x in enumerate(self.indices_end) if index < x)
        file_idx = index - self.indices_start[file_selector]
        file = self.files[file_selector]

        
        # select data
        if self.task == "forecast":
            x, y = self._get_item_forecast(file, file_idx)
        else:
            x, y = self._get_item_evolution(file, file_idx)

        # join lookback as channels
        new_shape = (-1, ) + x.shape[2:]
        x = x.reshape(new_shape)

        # permute axis for cloud data
        x, y = self._permute_axis(x, y)

        # get points
        points = file[self.points_selector][:]

        # additional transforms
        x, y, points = self.additional_transforms(x, y, points)
        
        return x, y, points

    
    def _get_item_forecast(self, file, file_idx):
        data_x = np.split(file[self.data_selector][file_idx:file_idx+self.lookback], 2, axis=1)[0]
        data_y = np.split(file[self.data_selector][file_idx+self.lookback:file_idx+self.lookback+self.rollout], 2, axis=1)[0]

        if self.equation == "wave":
            data_x = data_x[:, [0]]
            data_y = data_y[:, [0]]

        return data_x, data_y

    def _get_item_evolution(self, file, file_idx):
        data_x = np.split(file[self.data_selector][file_idx:file_idx+self.lookback], 2, axis=1)[0]
        data_y = np.split(file[self.data_selector][file_idx], 2, axis=0)[1]

        if self.equation == "wave":
            data_x = data_x[:, [0]]
            data_y = data_y[[0]]

        return data_x, data_y

    def _permute_axis(self, x, y):
        # before permutation dimensions are num_channels x num_points
        # should be num_points x num_channels
        if self.support == "cloud":
            x = x.transpose((1,0))
            y = y.transpose((2,1,0)) if self.task == "forecast" else y.transpose((1,0))
        return x, y

    
    def __len__(self):
        return sum(self.real_lengths)

    def additional_transforms(self, x, y, points):
        return x, y, points